{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Download and Extract the dataset\n",
        "NUMBER_OF_EXAMPLES = 1000 # Number of images to process\n",
        "\n",
        "local_zip = '/tmp/cats_and_dogs_filtered.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()\n",
        "\n",
        "base_dir = '/tmp/cats_and_dogs_filtered'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "\n",
        "# Define dictionaries for cats and dogs\n",
        "cats_dir = os.path.join(train_dir, 'cats')\n",
        "dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "\n",
        "# Initialize lists to store image data and labels\n",
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "# Load and process the images\n",
        "i = 0\n",
        "for img_name in os.listdir(cats_dir):\n",
        "  if i >= NUMBER_OF_EXAMPLES:\n",
        "    break\n",
        "    img_path = os.path.join(cats_dir, img_name)\n",
        "    im = Image.open(img_path).convert(\"RGB\")  # Open image and convert to RGB\n",
        "    im_resized = im.resize((150, 150))  # Resize to 150x150 pixels\n",
        "    x_train.append(np.array(im_resized))  # Convert image to NumPy array and append\n",
        "    y_train.append(1)  # Label for cat\n",
        "    i += 1\n",
        "\n",
        "for img_name in os.listdir(dogs_dir):\n",
        "    if i >= NUMBER_OF_EXAMPLES:\n",
        "        break\n",
        "    img_path = os.path.join(dogs_dir, img_name)\n",
        "    im = Image.open(img_path).convert(\"RGB\")  # Open image and convert to RGB\n",
        "    im_resized = im.resize((150, 150))  # Resize to 150x150 pixels\n",
        "    x_train.append(np.array(im_resized))  # Convert image to NumPy array and append\n",
        "    y_train.append(0)  # Label for dog\n",
        "    i += 1\n",
        "\n",
        "x_train = np.array(x_train) / 255.0 # Normalize pixel range to [0,1]\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "# Define the pre-trained ResNet50 model (without top layer)\n",
        "pretrained_model = tf.keras.applications.ResNet50(\n",
        "    include_top = False, # Exclude fully connected layers\n",
        "    input_shape = (150, 150, 3), # Input image size\n",
        "    pooling = 'avg',     # Use average pooling instead of fully connected layers\n",
        "    weights = 'imagenet' # Use weights to pre-trained on ImagetNet\n",
        ")\n",
        "\n",
        "# Freeze layers of the pre-trained model\n",
        "for layer in pretrained_model.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "# Add custom classification head on top of the pre-trained model\n",
        "model = tf.keras.Sequential([\n",
        "    pretrained_model,\n",
        "    tf.keras.layers.Dense(1024, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid') # sigmoid for binary classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    loss = 'binary_crossentropy',\n",
        "    optimizer = tf.keras.optimizers.Adam(),\n",
        "    metrics = ['accuracy']\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=32)\n",
        "\n",
        "# Fine tune the model (unfreeze some models)\n",
        "for layer in pretrained_model.layers[-20:]: # Unfreeze last 20 layers\n",
        "  layer.trainable = True\n",
        "\n",
        "# Re-compile the model w/ a lower learning rate for fine-tuning\n",
        "model.compile(\n",
        "    loss = 'binary_crossentropy',\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Continue training the model (fine-tuning the unfrozen layers)\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=32, callbacks=[early_stopping])\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kg_vOW_DR7dE",
        "outputId": "b95ca398-e303-4a73-9bc8-4d15c2383044"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0856\n",
            "Epoch 2/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 5.0731e-08\n",
            "Epoch 3/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 3.3325e-08\n",
            "Epoch 4/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 3.2261e-08\n",
            "Epoch 5/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 3.2551e-08\n",
            "Epoch 6/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 3.1843e-08\n",
            "Epoch 7/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 3.0251e-08\n",
            "Epoch 8/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 2.9907e-08\n",
            "Epoch 9/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 2.8958e-08\n",
            "Epoch 10/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 2.7263e-08\n",
            "Epoch 1/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 4s/step - accuracy: 1.0000 - loss: 3.9369e-09\n",
            "Epoch 2/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/callbacks/early_stopping.py:155: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: accuracy,loss\n",
            "  current = self.get_monitor_value(logs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 4s/step - accuracy: 1.0000 - loss: 4.1332e-09\n",
            "Epoch 3/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 4s/step - accuracy: 1.0000 - loss: 4.1027e-09\n",
            "Epoch 4/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 4s/step - accuracy: 1.0000 - loss: 4.0770e-09\n",
            "Epoch 5/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 4s/step - accuracy: 1.0000 - loss: 3.6259e-09\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x79b8d04792d0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}